{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o12ifaotXaMg"
      },
      "source": [
        "##### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "form",
        "colab": {},
        "colab_type": "code",
        "id": "1GBcPzQeXocT"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GSwlSaVxXuAE"
      },
      "source": [
        "# Closed Form Matting Energy\n",
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/graphics/blob/master/tensorflow_graphics/notebooks/matting.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/tensorflow/graphics/blob/master/tensorflow_graphics/notebooks/matting.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y3tbz-ntDzni"
      },
      "source": [
        "\n",
        "In image matting the input image $I$ is assumed to be a linear combination of a foreground image $F$ and a background image $B$. For a pixel $j$ of $I$, the color of the pixel can therefore be expressed as $I_j = \\alpha_j F_j +(1âˆ’\\alpha_j)B_j$,\n",
        "where $\\alpha_j$ is the foreground opacity for the pixel $j$. The opacity image made of all the $\\alpha_j$ pixels is called a matte. \n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://github.com/frcs/alternative-matting-laplacian/raw/master/GT04.png\" width=\"283\" height=\"200\" /\u003e\n",
        "\u003cimg src=\"https://github.com/frcs/alternative-matting-laplacian/raw/master/alpha0-GT04.png\" width=\"283\" height=\"200\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "Using a trimap (white for foreground, black for background, and gray for unknown pixels),\n",
        "\u003ccenter\u003e\n",
        "\u003cimg src=\"https://github.com/frcs/alternative-matting-laplacian/raw/master/trimap-GT04.png\" width=\"283\" height=\"200\" /\u003e\n",
        "\u003c/center\u003e\n",
        "\n",
        "an optimization can be formulated to retrieve the unknow pixel opacities. \n",
        "\n",
        "This colab demonstrates how to use the image matting loss implemented in TensorFlow Graphics to perform this optimization. This loss is derived from the paper untitled \"A Closed Form Solution to Natural Image Matting\" from Levin et al. The loss was \"tensorized\" inspired by \"Deep-Energy: Unsupervised Training of Deep Neural Networks\" from Golts et al.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9iWqeS9qYBAJ"
      },
      "source": [
        "## Setup \u0026 Imports\n",
        "If Tensorflow Graphics is not installed on your system, the following cell can install the Tensorflow Graphics package for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "X_v1AoLCYFp-"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow_graphics\n",
        "!git clone https://github.com/tensorflow/graphics.git\n",
        "!mv graphics/tensorflow_graphics tensorflow_graphics\n",
        "!rm -rf graphics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VSoQOLZXYGnL"
      },
      "source": [
        "Now that Tensorflow Graphics is installed, let's import everything needed to run the demos contained in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-JnFAN7Ndzi7"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow_graphics.image import matting\n",
        "\n",
        "tf.enable_eager_execution()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ni8fbo1OaHsj"
      },
      "source": [
        "## Imports the image and trimap.\n",
        "Download the image and trimap from alphamatting.com."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vBg2BCKPZCQ0"
      },
      "outputs": [],
      "source": [
        "# Downloads dataset from alphamatting.com\n",
        "!wget http://www.alphamatting.com/datasets/zip/input_training_lowres.zip\n",
        "!wget http://www.alphamatting.com/datasets/zip/trimap_training_lowres.zip\n",
        "!wget http://www.alphamatting.com/datasets/zip/gt_training_lowres.zip\n",
        "\n",
        "!unzip input_training_lowres.zip -d input_training_lowres\n",
        "!unzip trimap_training_lowres.zip -d trimap_training_lowres\n",
        "!unzip gt_training_lowres.zip -d gt_training_lowres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "E9uDtWFfE5lP"
      },
      "outputs": [],
      "source": [
        "# Reads and decode images.\n",
        "source = tf.read_file('input_training_lowres/GT04.png')\n",
        "source = tf.cast(tf.io.decode_png(source), tf.float64) / 255.0\n",
        "source = tf.expand_dims(source, axis=0)\n",
        "trimap = tf.read_file('trimap_training_lowres/Trimap1/GT04.png')\n",
        "trimap = tf.cast(tf.io.decode_png(trimap), tf.float64) / 255.0\n",
        "trimap = tf.reduce_mean(trimap, axis=-1, keepdims=True)\n",
        "trimap = tf.expand_dims(trimap, axis=0)\n",
        "gt_matte = tf.read_file('gt_training_lowres/GT04.png')\n",
        "gt_matte = tf.cast(tf.io.decode_png(gt_matte), tf.float64) / 255.0\n",
        "gt_matte = tf.reduce_mean(gt_matte, axis=-1, keepdims=True)\n",
        "gt_matte = tf.expand_dims(gt_matte, axis=0)\n",
        "\n",
        "# Resize images to improve performance.\n",
        "source = tf.image.resize(\n",
        "    source,\n",
        "    tf.shape(source)[1:3] // 2,\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "trimap = tf.image.resize(\n",
        "    trimap,\n",
        "    tf.shape(trimap)[1:3] // 2,\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "gt_matte = tf.image.resize(\n",
        "    gt_matte,\n",
        "    tf.shape(gt_matte)[1:3] // 2,\n",
        "    method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "# Shows images\n",
        "fig = plt.figure(figsize=(22, 18))\n",
        "axes = fig.add_subplot(1, 3, 1)\n",
        "axes.grid(False)\n",
        "axes.set_title('Input image', fontsize=14)\n",
        "plt.imshow(source[0, ...].numpy())\n",
        "axes = fig.add_subplot(1, 3, 2)\n",
        "axes.grid(False)\n",
        "axes.set_title('Input trimap', fontsize=14)\n",
        "plt.imshow(trimap[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "axes = fig.add_subplot(1, 3, 3)\n",
        "axes.grid(False)\n",
        "axes.set_title('GT matte', fontsize=14)\n",
        "plt.imshow(gt_matte[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gA7WTJI1Y0qZ"
      },
      "source": [
        "## Extract the foreground and background constraints from the trimap image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZzLFoL5_YSgX"
      },
      "outputs": [],
      "source": [
        "# Extracts the foreground and background constraints from the trimap image.\n",
        "foreground = tf.cast(tf.equal(trimap, 1.0), tf.float64)\n",
        "background = tf.cast(tf.equal(trimap, 0.0), tf.float64)\n",
        "\n",
        "# Shows foreground and background constraints.\n",
        "fig = plt.figure(figsize=(22, 18))\n",
        "axes = fig.add_subplot(1, 2, 1)\n",
        "axes.grid(False)\n",
        "axes.set_title('Foreground constraints', fontsize=14)\n",
        "plt.imshow(foreground[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "axes = fig.add_subplot(1, 2, 2)\n",
        "axes.grid(False)\n",
        "axes.set_title('Background constraints', fontsize=14)\n",
        "plt.imshow(background[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "INHsXVYHZdIi"
      },
      "source": [
        "## Setup \u0026 run the optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ya-cECcCajJ2"
      },
      "source": [
        "Setup the matting loss function using TensorFlow Graphics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BYSuaxkRaaxz"
      },
      "outputs": [],
      "source": [
        "# Initializes the matte with random values.\n",
        "matte_shape = tf.concat((tf.shape(source)[:-1], (1,)), axis=-1)\n",
        "matte = tf.Variable(\n",
        "    tf.random.uniform(\n",
        "        shape=matte_shape, minval=0.0, maxval=1.0, dtype=tf.float64))\n",
        "# Creates the closed form matting Laplacian\n",
        "L, _ = matting.build_matrices(source)\n",
        "\n",
        "\n",
        "# Function computing the loss and applying the gradient.\n",
        "@tf.function\n",
        "def optimize(optimizer):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(matte)\n",
        "    # Computes a loss enforcing the trimap constraints.\n",
        "    constraints = tf.reduce_mean((foreground + background) *\n",
        "                                 tf.math.squared_difference(matte, foreground))\n",
        "    # Computes the matting loss.\n",
        "    smoothness = matting.loss(matte, L)\n",
        "    # Sums up the constraint and matting losses.\n",
        "    total_loss = 100 * constraints + smoothness\n",
        "  # Computes and applies the gradient to the matte.\n",
        "  g = tape.gradient(total_loss, [matte])\n",
        "  optimizer.apply_gradients(zip(g, (matte,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "725a7c42agiP"
      },
      "source": [
        "Run the Adam optimizer for 400 iterations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d1K0GaEHYWIl"
      },
      "outputs": [],
      "source": [
        "# Runs the Adam optimizer for 400 iterations.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=1.0)\n",
        "nb_iterations = 400\n",
        "for it in range(nb_iterations):\n",
        "  optimize(optimizer)\n",
        "\n",
        "# Displays the result.\n",
        "fig = plt.figure(figsize=(22, 18))\n",
        "axes = fig.add_subplot(1, 4, 1)\n",
        "axes.grid(False)\n",
        "axes.set_title('Input image', fontsize=14)\n",
        "plt.imshow(source[0, ...].numpy())\n",
        "axes = fig.add_subplot(1, 4, 2)\n",
        "axes.grid(False)\n",
        "axes.set_title('Input trimap', fontsize=14)\n",
        "plt.imshow(trimap[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "axes = fig.add_subplot(1, 4, 3)\n",
        "axes.grid(False)\n",
        "axes.set_title('Matte', fontsize=14)\n",
        "plt.imshow(matte[0, ..., 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "axes = fig.add_subplot(1, 4, 4)\n",
        "axes.grid(False)\n",
        "axes.set_title('Input image x Matte', fontsize=14)\n",
        "plt.imshow((source * matte)[0, ...].numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//vr/perception/makkari/colab:makkari",
        "kind": "private"
      },
      "name": "Matting.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
